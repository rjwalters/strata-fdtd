/**
 * HDF5 Loader for FDTD simulation results.
 *
 * Loads simulation data from HDF5 files generated by the Python FDTD solver.
 * Uses h5wasm for WebAssembly-based HDF5 parsing in the browser.
 *
 * HDF5 file structure (from issue #211):
 * ```
 * results_{hash}.h5
 * ├─ /metadata (attributes)
 * │  ├─ script_hash, script_content, created_at, solver_version, ...
 * │
 * ├─ /grid (group)
 * │  ├─ shape, resolution, extent, is_uniform
 * │
 * ├─ /materials (dataset: uint8)
 * │
 * ├─ /simulation (attributes)
 * │  ├─ timestep, num_steps, cfl_number, total_time, pml_thickness
 * │
 * ├─ /fields (group)
 * │  └─ pressure (dataset: float32, shape=[num_steps, nz, ny, nx])
 * │
 * ├─ /sources (group)
 * │
 * └─ /probes (group)
 *    └─ probe_0 (dataset: float32, shape=[num_steps])
 * ```
 *
 * @module loaders/hdf5
 */

import * as h5wasm from "h5wasm";
import type { Geometry, ProbeData, SimulationMetadata } from "./types";

// =============================================================================
// Types
// =============================================================================

/**
 * HDF5 simulation data structure.
 * Contains all data loaded from an HDF5 file.
 */
export interface HDF5SimulationData {
  metadata: HDF5Metadata;
  grid: HDF5Grid;
  simulation: HDF5SimulationParams;
  materials: Uint8Array | null;
  materialMap: Record<string, string>;
  numSteps: number;
  timestep: number;
  probes: ProbeData;
  sources: HDF5Source[];
  /** Geometry mask derived from materials (true = air, false = solid) */
  geometry: Geometry | null;
}

/**
 * HDF5 metadata attributes.
 */
export interface HDF5Metadata {
  scriptHash: string;
  scriptContent: string;
  createdAt: string;
  solverVersion: string;
  backend?: string;
  numThreads?: number;
  totalRuntimeSeconds?: number;
}

/**
 * HDF5 grid information.
 */
export interface HDF5Grid {
  shape: [number, number, number];
  resolution: number;
  extent: [number, number, number];
  isUniform: boolean;
}

/**
 * HDF5 simulation parameters.
 */
export interface HDF5SimulationParams {
  timestep: number;
  numSteps: number;
  cflNumber: number;
  totalTime: number;
  pmlThickness?: number;
}

/**
 * HDF5 source definition.
 */
export interface HDF5Source {
  type: string;
  position: [number, number, number];
  frequency?: number;
  bandwidth?: number;
  amplitude?: number;
}

/**
 * Progress callback for loading operations.
 */
export type ProgressCallback = (loaded: number, total: number) => void;

/**
 * Options for loading HDF5 files.
 */
export interface HDF5LoadOptions {
  /** Progress callback for file loading */
  onProgress?: ProgressCallback;
  /** AbortSignal for cancellation */
  signal?: AbortSignal;
  /** Max file size in bytes (default: 2GB) */
  maxFileSize?: number;
}

/**
 * Result from loading HDF5 from URL, including both parsed data and raw buffer.
 * The buffer can be reused for timestep loading without re-fetching.
 */
export interface HDF5URLLoadResult {
  /** Parsed simulation data */
  data: HDF5SimulationData;
  /** Raw file buffer for subsequent timestep loading */
  buffer: Uint8Array;
  /** Filename extracted from URL */
  filename: string;
}

// =============================================================================
// Module State
// =============================================================================

let h5wasmModule: typeof h5wasm.Module | null = null;
let h5wasmFS: typeof h5wasm.FS | null = null;

/**
 * Initialize h5wasm WebAssembly module.
 * Called automatically on first use.
 */
async function ensureH5wasmReady(): Promise<void> {
  if (!h5wasmModule) {
    const module = await h5wasm.ready;
    h5wasmModule = module;
    h5wasmFS = h5wasm.FS;
  }
}

// =============================================================================
// Main Loader Functions
// =============================================================================

/**
 * Load simulation data from an HDF5 file.
 *
 * @param file - File object from file input or drag-drop
 * @param options - Loading options
 * @returns Parsed simulation data
 */
export async function loadHDF5File(
  file: File,
  options: HDF5LoadOptions = {}
): Promise<HDF5SimulationData> {
  const maxSize = options.maxFileSize ?? 2 * 1024 * 1024 * 1024; // 2GB default

  if (file.size > maxSize) {
    throw new Error(
      `File size (${formatBytes(file.size)}) exceeds limit (${formatBytes(maxSize)})`
    );
  }

  // Read file as ArrayBuffer
  const buffer = await readFileAsArrayBuffer(file, options);

  // Parse HDF5
  return parseHDF5Buffer(new Uint8Array(buffer), file.name);
}

/**
 * Load simulation data from a URL.
 *
 * Returns both the parsed data and the raw buffer to avoid needing to
 * re-fetch the file for subsequent timestep loading.
 *
 * @param url - URL to HDF5 file
 * @param options - Loading options
 * @returns Parsed simulation data, raw buffer, and filename
 */
export async function loadHDF5FromURL(
  url: string,
  options: HDF5LoadOptions = {}
): Promise<HDF5URLLoadResult> {
  const response = await fetch(url, { signal: options.signal });

  if (!response.ok) {
    throw new Error(`Failed to fetch: ${response.status} ${response.statusText}`);
  }

  const contentLength = response.headers.get("content-length");
  const total = contentLength ? parseInt(contentLength, 10) : 0;
  const maxSize = options.maxFileSize ?? 2 * 1024 * 1024 * 1024;

  if (total > maxSize) {
    throw new Error(
      `File size (${formatBytes(total)}) exceeds limit (${formatBytes(maxSize)})`
    );
  }

  const filename = url.split("/").pop() || "simulation.h5";

  if (!response.body) {
    // Fallback for browsers without ReadableStream support
    const arrayBuffer = await response.arrayBuffer();
    const buffer = new Uint8Array(arrayBuffer);
    const data = await parseHDF5Buffer(buffer, filename);
    return { data, buffer, filename };
  }

  // Stream with progress
  const reader = response.body.getReader();
  const chunks: Uint8Array[] = [];
  let loaded = 0;

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    chunks.push(value);
    loaded += value.length;

    if (options.onProgress) {
      options.onProgress(loaded, total || loaded);
    }
  }

  // Combine chunks
  const buffer = new Uint8Array(loaded);
  let offset = 0;
  for (const chunk of chunks) {
    buffer.set(chunk, offset);
    offset += chunk.length;
  }

  const data = await parseHDF5Buffer(buffer, filename);
  return { data, buffer, filename };
}

/**
 * Load a single pressure timestep from an open HDF5 file.
 */
export async function loadTimestep(
  h5file: h5wasm.File,
  step: number
): Promise<Float32Array> {
  await ensureH5wasmReady();

  const pressureEntity = h5file.get("/fields/pressure");
  if (!pressureEntity || !(pressureEntity instanceof h5wasm.Dataset)) {
    throw new Error("Pressure dataset not found in HDF5 file");
  }

  const dataset = pressureEntity;
  const datasetShape = dataset.shape;

  if (!datasetShape || step < 0 || step >= datasetShape[0]) {
    throw new Error(`Invalid timestep ${step}`);
  }

  // Read single timestep slice
  const slice = dataset.slice([[step, step + 1]]);

  if (slice instanceof Float32Array) {
    return slice;
  }

  // Handle other array types
  if (slice && typeof slice === "object" && "length" in slice) {
    return new Float32Array(slice as ArrayLike<number>);
  }

  throw new Error("Unexpected data type from pressure dataset");
}

// =============================================================================
// Internal Helpers
// =============================================================================

/**
 * Parse HDF5 data from a Uint8Array buffer.
 */
async function parseHDF5Buffer(
  buffer: Uint8Array,
  filename: string
): Promise<HDF5SimulationData> {
  await ensureH5wasmReady();

  if (!h5wasmFS) {
    throw new Error("h5wasm FS not initialized");
  }

  // Write buffer to virtual filesystem
  const virtualPath = `/${filename}`;
  h5wasmFS.writeFile(virtualPath, buffer);

  // Open HDF5 file from virtual filesystem
  const h5file = new h5wasm.File(virtualPath, "r");

  try {
    // Read metadata
    const metadata = readMetadata(h5file);

    // Read grid
    const grid = readGrid(h5file);

    // Read simulation params
    const simulation = readSimulationParams(h5file);

    // Read materials (optional)
    const { materials, materialMap } = readMaterials(h5file);

    // Create geometry mask from materials
    const geometry = materials ? createGeometryFromMaterials(materials, grid.shape) : null;

    // Read probes
    const probes = readProbes(h5file, simulation.timestep);

    // Read sources
    const sources = readSources(h5file);

    return {
      metadata,
      grid,
      simulation,
      materials,
      materialMap,
      numSteps: simulation.numSteps,
      timestep: simulation.timestep,
      probes,
      sources,
      geometry,
    };
  } finally {
    h5file.close();
    // Clean up virtual file
    try {
      h5wasmFS.unlink(virtualPath);
    } catch {
      // Ignore cleanup errors
    }
  }
}

/**
 * Read metadata attributes from /metadata.
 */
function readMetadata(h5file: h5wasm.File): HDF5Metadata {
  const metadataEntity = h5file.get("/metadata");
  if (!metadataEntity) {
    return {
      scriptHash: "",
      scriptContent: "",
      createdAt: new Date().toISOString(),
      solverVersion: "unknown",
    };
  }

  // Check if it's a group with attrs
  if (!(metadataEntity instanceof h5wasm.Group) && !(metadataEntity instanceof h5wasm.Dataset)) {
    return {
      scriptHash: "",
      scriptContent: "",
      createdAt: new Date().toISOString(),
      solverVersion: "unknown",
    };
  }

  const attrs = metadataEntity.attrs;

  return {
    scriptHash: getAttrString(attrs, "script_hash") ?? "",
    scriptContent: getAttrString(attrs, "script_content") ?? "",
    createdAt: getAttrString(attrs, "created_at") ?? new Date().toISOString(),
    solverVersion: getAttrString(attrs, "solver_version") ?? "unknown",
    backend: getAttrString(attrs, "backend"),
    numThreads: getAttrNumber(attrs, "num_threads"),
    totalRuntimeSeconds: getAttrNumber(attrs, "total_runtime_seconds"),
  };
}

/**
 * Read grid information from /grid.
 */
function readGrid(h5file: h5wasm.File): HDF5Grid {
  const gridEntity = h5file.get("/grid");
  if (!gridEntity || !(gridEntity instanceof h5wasm.Group)) {
    throw new Error("Grid group not found in HDF5 file");
  }

  // Read shape
  const shapeEntity = h5file.get("/grid/shape");
  let shape: [number, number, number] = [10, 10, 10];
  if (shapeEntity instanceof h5wasm.Dataset) {
    const shapeValue = shapeEntity.value;
    if (Array.isArray(shapeValue) && shapeValue.length >= 3) {
      shape = [Number(shapeValue[0]), Number(shapeValue[1]), Number(shapeValue[2])];
    }
  } else if (gridEntity.attrs.shape) {
    const shapeValue = gridEntity.attrs.shape.value;
    if (Array.isArray(shapeValue) && shapeValue.length >= 3) {
      shape = [Number(shapeValue[0]), Number(shapeValue[1]), Number(shapeValue[2])];
    }
  }

  // Read resolution
  let resolution = 0.01;
  const resolutionEntity = h5file.get("/grid/resolution");
  if (resolutionEntity instanceof h5wasm.Dataset) {
    const resValue = resolutionEntity.value;
    if (typeof resValue === "number") {
      resolution = resValue;
    } else if (Array.isArray(resValue)) {
      resolution = Number(resValue[0]);
    }
  } else if (gridEntity.attrs.resolution) {
    const resValue = gridEntity.attrs.resolution.value;
    if (typeof resValue === "number") {
      resolution = resValue;
    }
  }

  // Read extent
  let extent: [number, number, number] = [
    shape[0] * resolution,
    shape[1] * resolution,
    shape[2] * resolution,
  ];
  const extentEntity = h5file.get("/grid/extent");
  if (extentEntity instanceof h5wasm.Dataset) {
    const extValue = extentEntity.value;
    if (Array.isArray(extValue) && extValue.length >= 3) {
      extent = [Number(extValue[0]), Number(extValue[1]), Number(extValue[2])];
    }
  }

  // Read is_uniform
  let isUniform = true;
  if (gridEntity.attrs.is_uniform) {
    const uniformValue = gridEntity.attrs.is_uniform.value;
    isUniform = Boolean(uniformValue);
  }

  return { shape, resolution, extent, isUniform };
}

/**
 * Read simulation parameters from /simulation.
 */
function readSimulationParams(h5file: h5wasm.File): HDF5SimulationParams {
  const simEntity = h5file.get("/simulation");

  // Default values
  let timestep = 1e-6;
  let numSteps = 0;
  let cflNumber = 0.5;
  let totalTime = 0;
  let pmlThickness: number | undefined;

  // Try to get numSteps from pressure dataset shape
  const pressureEntity = h5file.get("/fields/pressure");
  if (pressureEntity instanceof h5wasm.Dataset && pressureEntity.shape) {
    numSteps = pressureEntity.shape[0];
  }

  // Read from /simulation group if exists
  if (simEntity && (simEntity instanceof h5wasm.Group || simEntity instanceof h5wasm.Dataset)) {
    const attrs = simEntity.attrs;
    timestep = getAttrNumber(attrs, "timestep") ?? timestep;
    numSteps = getAttrNumber(attrs, "num_steps") ?? numSteps;
    cflNumber = getAttrNumber(attrs, "cfl_number") ?? cflNumber;
    totalTime = getAttrNumber(attrs, "total_time") ?? numSteps * timestep;
    pmlThickness = getAttrNumber(attrs, "pml_thickness");
  }

  return { timestep, numSteps, cflNumber, totalTime, pmlThickness };
}

/**
 * Read materials dataset and map from /materials.
 */
function readMaterials(
  h5file: h5wasm.File
): { materials: Uint8Array | null; materialMap: Record<string, string> } {
  const materialsEntity = h5file.get("/materials");
  if (!materialsEntity || !(materialsEntity instanceof h5wasm.Dataset)) {
    return { materials: null, materialMap: {} };
  }

  const data = materialsEntity.value;

  let materials: Uint8Array;
  if (data instanceof Uint8Array) {
    materials = data;
  } else if (ArrayBuffer.isView(data)) {
    materials = new Uint8Array((data as ArrayBufferView).buffer);
  } else if (Array.isArray(data)) {
    // Flatten nested arrays
    const flattened: number[] = [];
    const flatten = (arr: unknown[]): void => {
      for (const item of arr) {
        if (Array.isArray(item)) {
          flatten(item);
        } else {
          flattened.push(Number(item));
        }
      }
    };
    flatten(data);
    materials = new Uint8Array(flattened);
  } else {
    return { materials: null, materialMap: {} };
  }

  // Read material map from attribute
  let materialMap: Record<string, string> = {};
  if (materialsEntity.attrs.material_map) {
    const mapValue = materialsEntity.attrs.material_map.value;
    if (typeof mapValue === "string") {
      try {
        materialMap = JSON.parse(mapValue);
      } catch {
        // Ignore parse errors
      }
    } else if (typeof mapValue === "object" && mapValue !== null) {
      materialMap = mapValue as unknown as Record<string, string>;
    }
  }

  return { materials, materialMap };
}

/**
 * Create geometry mask from materials array.
 * Material index 0 is assumed to be air (true), others are solid (false).
 */
function createGeometryFromMaterials(
  materials: Uint8Array,
  shape: [number, number, number]
): Geometry {
  const mask = new Uint8Array(materials.length);
  for (let i = 0; i < materials.length; i++) {
    mask[i] = materials[i] === 0 ? 1 : 0;
  }
  return { mask, shape };
}

/**
 * Read probe data from /probes.
 */
function readProbes(h5file: h5wasm.File, timestep: number): ProbeData {
  const probesEntity = h5file.get("/probes");
  if (!probesEntity || !(probesEntity instanceof h5wasm.Group)) {
    return {
      sampleRate: 1 / timestep,
      dt: timestep,
      duration: 0,
      nSamples: 0,
      probes: {},
    };
  }

  const probes: ProbeData["probes"] = {};
  let maxSamples = 0;

  for (const key of probesEntity.keys()) {
    const probeEntity = h5file.get(`/probes/${key}`);
    if (!probeEntity || !(probeEntity instanceof h5wasm.Dataset)) continue;

    const data = probeEntity.value;

    let probeData: Float32Array;
    if (data instanceof Float32Array) {
      probeData = data;
    } else if (ArrayBuffer.isView(data)) {
      probeData = new Float32Array((data as ArrayBufferView).buffer);
    } else if (Array.isArray(data)) {
      // Flatten nested arrays
      const flattened: number[] = [];
      const flattenArr = (arr: unknown[]): void => {
        for (const item of arr) {
          if (Array.isArray(item)) {
            flattenArr(item);
          } else {
            flattened.push(Number(item));
          }
        }
      };
      flattenArr(data);
      probeData = new Float32Array(flattened);
    } else {
      continue;
    }

    maxSamples = Math.max(maxSamples, probeData.length);

    // Read position attribute
    let position: [number, number, number] = [0, 0, 0];
    if (probeEntity.attrs.position) {
      const posValue = probeEntity.attrs.position.value;
      if (Array.isArray(posValue) && posValue.length >= 3) {
        position = [Number(posValue[0]), Number(posValue[1]), Number(posValue[2])];
      }
    }

    probes[key] = { position, data: probeData };
  }

  return {
    sampleRate: 1 / timestep,
    dt: timestep,
    duration: maxSamples * timestep,
    nSamples: maxSamples,
    probes,
  };
}

/**
 * Read source definitions from /sources.
 */
function readSources(h5file: h5wasm.File): HDF5Source[] {
  const sourcesEntity = h5file.get("/sources");
  if (!sourcesEntity || !(sourcesEntity instanceof h5wasm.Group)) {
    return [];
  }

  const sources: HDF5Source[] = [];

  for (const key of sourcesEntity.keys()) {
    const sourceEntity = h5file.get(`/sources/${key}`);
    if (!sourceEntity) continue;

    // Sources can be groups or datasets with attrs
    if (!(sourceEntity instanceof h5wasm.Group) && !(sourceEntity instanceof h5wasm.Dataset)) {
      continue;
    }

    const attrs = sourceEntity.attrs;

    let position: [number, number, number] = [0, 0, 0];
    if (attrs.position) {
      const posValue = attrs.position.value;
      if (Array.isArray(posValue) && posValue.length >= 3) {
        position = [Number(posValue[0]), Number(posValue[1]), Number(posValue[2])];
      }
    }

    sources.push({
      type: getAttrString(attrs, "type") ?? "unknown",
      position,
      frequency: getAttrNumber(attrs, "frequency"),
      bandwidth: getAttrNumber(attrs, "bandwidth"),
      amplitude: getAttrNumber(attrs, "amplitude"),
    });
  }

  return sources;
}

/**
 * Get string attribute value.
 */
function getAttrString(
  attrs: Record<string, h5wasm.Attribute>,
  name: string
): string | undefined {
  const attr = attrs[name];
  if (!attr) return undefined;
  const val = attr.value;
  if (typeof val === "string") return val;
  if (Array.isArray(val) && val.length > 0) return String(val[0]);
  return undefined;
}

/**
 * Get numeric attribute value.
 */
function getAttrNumber(
  attrs: Record<string, h5wasm.Attribute>,
  name: string
): number | undefined {
  const attr = attrs[name];
  if (!attr) return undefined;
  const val = attr.value;
  if (typeof val === "number") return val;
  if (Array.isArray(val) && val.length > 0 && typeof val[0] === "number") {
    return val[0];
  }
  return undefined;
}

/**
 * Read file as ArrayBuffer with progress.
 */
function readFileAsArrayBuffer(
  file: File,
  options: HDF5LoadOptions
): Promise<ArrayBuffer> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();

    reader.onload = () => {
      resolve(reader.result as ArrayBuffer);
    };

    reader.onerror = () => {
      reject(new Error(`Failed to read file: ${reader.error?.message}`));
    };

    reader.onprogress = (event) => {
      if (event.lengthComputable && options.onProgress) {
        options.onProgress(event.loaded, event.total);
      }
    };

    if (options.signal) {
      options.signal.addEventListener("abort", () => {
        reader.abort();
        reject(new Error("File read aborted"));
      });
    }

    reader.readAsArrayBuffer(file);
  });
}

/**
 * Format bytes as human-readable string.
 */
function formatBytes(bytes: number): string {
  if (bytes < 1024) return `${bytes} B`;
  if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`;
  if (bytes < 1024 * 1024 * 1024) return `${(bytes / (1024 * 1024)).toFixed(1)} MB`;
  return `${(bytes / (1024 * 1024 * 1024)).toFixed(2)} GB`;
}

// =============================================================================
// Conversion to Existing Types
// =============================================================================

/**
 * Convert HDF5 data to SimulationMetadata format.
 * Allows using HDF5 data with existing visualization components.
 */
export function toSimulationMetadata(data: HDF5SimulationData): SimulationMetadata {
  return {
    grid: {
      shape: data.grid.shape,
      resolution: data.grid.resolution,
      physicalSize: data.grid.extent,
    },
    physics: {
      c: 343,
      rho: 1.225,
    },
    simulation: {
      dt: data.simulation.timestep,
      cflLimit: data.simulation.cflNumber,
      currentTime: data.simulation.totalTime,
      stepCount: data.simulation.numSteps,
    },
    probes: Object.fromEntries(
      Object.entries(data.probes.probes).map(([name, probe]) => [
        name,
        { position: probe.position },
      ])
    ),
    sources: data.sources.map((source) => ({
      type: source.type,
      position: source.position,
      frequency: source.frequency ?? 0,
      bandwidth: source.bandwidth ?? 0,
    })),
    extra: {
      scriptHash: data.metadata.scriptHash,
      createdAt: data.metadata.createdAt,
      solverVersion: data.metadata.solverVersion,
    },
  };
}
